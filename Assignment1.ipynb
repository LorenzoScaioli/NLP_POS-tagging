{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WeCeITXoxLf",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
    "\n",
    "**Keywords**: POS tagging, Sequence labelling, RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# Contact\n",
    "\n",
    "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
    "\n",
    "Teaching Assistants:\n",
    "\n",
    "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
    "* Eleonora Mancini -> e.mancini@unibo.it\n",
    "\n",
    "Professor:\n",
    "\n",
    "* Paolo Torroni -> p.torroni@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "You are tasked to address the task of POS tagging.\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/pos_tagging.png\" alt=\"POS tagging\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 1 - 0.5 points] Corpus\n",
    "\n",
    "You are going to work with the [Penn TreeBank corpus](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip).\n",
    "\n",
    "**Ignore** the numeric value in the third column, use **only** the words/symbols and their POS label.\n",
    "\n",
    "### Example\n",
    "\n",
    "```Pierre\tNNP\t2\n",
    "Vinken\tNNP\t8\n",
    ",\t,\t2\n",
    "61\tCD\t5\n",
    "years\tNNS\t6\n",
    "old\tJJ\t2\n",
    ",\t,\t2\n",
    "will\tMD\t0\n",
    "join\tVB\t8\n",
    "the\tDT\t11\n",
    "board\tNN\t9\n",
    "as\tIN\t9\n",
    "a\tDT\t15\n",
    "nonexecutive\tJJ\t15\n",
    "director\tNN\t12\n",
    "Nov.\tNNP\t9\n",
    "29\tCD\t16\n",
    ".\t.\t8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Splits\n",
    "\n",
    "The corpus contains 200 documents.\n",
    "\n",
    "   * **Train**: Documents 1-100\n",
    "   * **Validation**: Documents 101-150\n",
    "   * **Test**: Documents 151-199"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* **Download** the corpus.\n",
    "* **Encode** the corpus into a pandas.DataFrame object.\n",
    "* **Split** it in training, validation, and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file management\n",
    "import sys\n",
    "import shutil\n",
    "import urllib\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# dataframe management\n",
    "import pandas as pd\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "\n",
    "# for readability\n",
    "from typing import Iterable\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(download_path: Path, url: str):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=download_path, reporthook=t.update_to)\n",
    "\n",
    "        \n",
    "def download_dataset(download_path: Path, url: str):\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_url(url=url, download_path=download_path)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "def extract_dataset(download_path: Path, extract_path: Path):\n",
    "    print(\"Extracting dataset... (it may take a while...)\")\n",
    "    \n",
    "    with zipfile.ZipFile(download_path) as loaded_tar:\n",
    "        loaded_tar.extractall(path=extract_path, pwd=None)\n",
    "    print(\"Extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory: /Users/giacomopiergentili/Developer/NLP/Assignment1/NLP_POS-tagging\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
    "dataset_name = \"dependency_treebank\"\n",
    "\n",
    "print(f\"Current work directory: {Path.cwd()}\")\n",
    "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    dataset_folder.mkdir(parents=True)\n",
    "\n",
    "dataset_tar_path = dataset_folder.joinpath(\"dependency_treebank.zip\")\n",
    "dataset_path = dataset_folder.joinpath(dataset_name)\n",
    "\n",
    "if not dataset_tar_path.exists():\n",
    "    download_dataset(dataset_tar_path, url)\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    extract_dataset(dataset_tar_path, dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode and Split\n",
    "\n",
    "The aim of the code below is to find a way to create a dataframe starting from all the files downloaded before.\n",
    "For every downloaded file, we check the number through the function find_number(), we decide if it belongs to train, validation or test given that number, we then split it into rows to get the word and the POS and to check where a phrase ends. Given all this informations we can create a list whose columns are: \n",
    "1. num_file: the number of the file\n",
    "2. phrase_id: the id of the phrase contained in a file \n",
    "3. text: the text that has to be analyzed\n",
    "4. pos: the tag assigned to the text\n",
    "5. split: the split to which the text belongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_number(string):\n",
    "    \"\"\"\n",
    "    This function finds the number written in a string.\n",
    "    \"\"\"\n",
    "    return re.findall(r'\\d+', string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_rows = []\n",
    "id = 0\n",
    "\n",
    "folder = dataset_folder.joinpath(dataset_name)\n",
    "for file_path in folder.glob('*.dp'):\n",
    "    num_file = int(find_number(file_path.name)[0])\n",
    "    id = 1\n",
    "    \n",
    "    with file_path.open(mode='r', encoding='utf-8') as text_file:\n",
    "        \n",
    "        if num_file < 101:\n",
    "            split = \"train\"\n",
    "        elif num_file >= 101 and num_file < 151:\n",
    "            split = \"validation\"\n",
    "        else:\n",
    "            split = \"test\"\n",
    "\n",
    "        for row in text_file.readlines():\n",
    "            if row=='\\n' or row=='':\n",
    "                id += 1\n",
    "\n",
    "            else:\n",
    "                text, pos, _ = row.split('\\t')\n",
    "\n",
    "                dataframe_row = {\n",
    "                    \"num_file\": num_file,\n",
    "                    \"phrase_id\": str(num_file) + \"_\" + str(id),\n",
    "                    \"text\": text,\n",
    "                    \"pos\": pos,\n",
    "                    \"split\": split\n",
    "                }\n",
    "\n",
    "                dataframe_rows.append(dataframe_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_file</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>In</td>\n",
       "      <td>IN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>reference</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>your</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>Oct.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>9</td>\n",
       "      <td>CD</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>page-one</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>article</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>``</td>\n",
       "      <td>``</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>Barbara</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>Bush</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>Earns</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>Even</td>\n",
       "      <td>RB</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>Higher</td>\n",
       "      <td>JJR</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>Ratings</td>\n",
       "      <td>NNS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>Than</td>\n",
       "      <td>IN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>President</td>\n",
       "      <td>NNP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>''</td>\n",
       "      <td>''</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>it</td>\n",
       "      <td>PRP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>regrettable</td>\n",
       "      <td>JJ</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>that</td>\n",
       "      <td>IN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>you</td>\n",
       "      <td>PRP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>must</td>\n",
       "      <td>MD</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>continually</td>\n",
       "      <td>RB</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>define</td>\n",
       "      <td>VB</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>blacks</td>\n",
       "      <td>NNS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>by</td>\n",
       "      <td>IN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>our</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>negatives</td>\n",
       "      <td>NNS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>``</td>\n",
       "      <td>``</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>Among</td>\n",
       "      <td>IN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>liberals</td>\n",
       "      <td>NNS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>60</td>\n",
       "      <td>CD</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>%</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>positive</td>\n",
       "      <td>JJ</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>views</td>\n",
       "      <td>NNS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>her</td>\n",
       "      <td>PRP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>while</td>\n",
       "      <td>IN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>50</td>\n",
       "      <td>CD</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>%</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>approve</td>\n",
       "      <td>VBP</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>president</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>'s</td>\n",
       "      <td>POS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>job</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>performance</td>\n",
       "      <td>NN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>95</td>\n",
       "      <td>95_1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>95</td>\n",
       "      <td>95_2</td>\n",
       "      <td>In</td>\n",
       "      <td>IN</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_file phrase_id         text   pos  split\n",
       "0         95      95_1           In    IN  train\n",
       "1         95      95_1    reference    NN  train\n",
       "2         95      95_1           to    TO  train\n",
       "3         95      95_1         your  PRP$  train\n",
       "4         95      95_1         Oct.   NNP  train\n",
       "5         95      95_1            9    CD  train\n",
       "6         95      95_1     page-one    NN  train\n",
       "7         95      95_1      article    NN  train\n",
       "8         95      95_1           ``    ``  train\n",
       "9         95      95_1      Barbara   NNP  train\n",
       "10        95      95_1         Bush   NNP  train\n",
       "11        95      95_1        Earns   VBZ  train\n",
       "12        95      95_1         Even    RB  train\n",
       "13        95      95_1       Higher   JJR  train\n",
       "14        95      95_1      Ratings   NNS  train\n",
       "15        95      95_1         Than    IN  train\n",
       "16        95      95_1          the    DT  train\n",
       "17        95      95_1    President   NNP  train\n",
       "18        95      95_1            ,     ,  train\n",
       "19        95      95_1           ''    ''  train\n",
       "20        95      95_1           it   PRP  train\n",
       "21        95      95_1           is   VBZ  train\n",
       "22        95      95_1  regrettable    JJ  train\n",
       "23        95      95_1         that    IN  train\n",
       "24        95      95_1          you   PRP  train\n",
       "25        95      95_1         must    MD  train\n",
       "26        95      95_1  continually    RB  train\n",
       "27        95      95_1       define    VB  train\n",
       "28        95      95_1       blacks   NNS  train\n",
       "29        95      95_1           by    IN  train\n",
       "30        95      95_1          our  PRP$  train\n",
       "31        95      95_1    negatives   NNS  train\n",
       "32        95      95_1            :     :  train\n",
       "33        95      95_1           ``    ``  train\n",
       "34        95      95_1        Among    IN  train\n",
       "35        95      95_1     liberals   NNS  train\n",
       "36        95      95_1            ,     ,  train\n",
       "37        95      95_1           60    CD  train\n",
       "38        95      95_1            %    NN  train\n",
       "39        95      95_1         have   VBP  train\n",
       "40        95      95_1     positive    JJ  train\n",
       "41        95      95_1        views   NNS  train\n",
       "42        95      95_1           of    IN  train\n",
       "43        95      95_1          her   PRP  train\n",
       "44        95      95_1            ,     ,  train\n",
       "45        95      95_1        while    IN  train\n",
       "46        95      95_1           50    CD  train\n",
       "47        95      95_1            %    NN  train\n",
       "48        95      95_1      approve   VBP  train\n",
       "49        95      95_1           of    IN  train\n",
       "50        95      95_1          the    DT  train\n",
       "51        95      95_1    president    NN  train\n",
       "52        95      95_1           's   POS  train\n",
       "53        95      95_1          job    NN  train\n",
       "54        95      95_1  performance    NN  train\n",
       "55        95      95_1            .     .  train\n",
       "56        95      95_2           In    IN  train"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataframe_rows)\n",
    "df.head(57)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 2 - 0.5 points] Text encoding\n",
    "\n",
    "To train a neural POS tagger, you first need to encode text into numerical format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Embed words using **GloVe embeddings**.\n",
    "* You are **free** to pick any embedding dimension.\n",
    "* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 3 - 1.0 points] Model definition\n",
    "\n",
    "You are now tasked to define your neural POS tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
    "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
    "\n",
    "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
    "* **Model 2**: add an additional Dense layer to the Baseline model.\n",
    "\n",
    "* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n",
    "\n",
    "**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 4 - 1.0 points] Metrics\n",
    "\n",
    "Before training the models, you are tasked to define the evaluation metrics for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Evaluate your models using macro F1-score, compute over **all** tokens.\n",
    "* **Concatenate** all tokens in a data split to compute the F1-score. (**Hint**: accumulate FP, TP, FN, TN iteratively) \n",
    "* **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Note**: What about OOV tokens?\n",
    "   * All the tokens in the **training** set that are not in GloVe are **not** considered as OOV\n",
    "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **static** embedding.\n",
    "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 5 - 1.0 points] Training and Evaluation\n",
    "\n",
    "You are now tasked to train and evaluate the Baseline, Model 1, and Model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Train **all** models on the train set.\n",
    "* Evaluate **all** models on the validation set.\n",
    "* Compute metrics on the validation set.\n",
    "* Pick **at least** three seeds for robust estimation.\n",
    "* Pick the **best** performing model according to the observed validation set performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 6 - 1.0 points] Error Analysis\n",
    "\n",
    "You are tasked to evaluate your best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Compare the errors made on the validation and test sets.\n",
    "* Aggregate model errors into categories (if possible) \n",
    "* Comment the about errors and propose possible solutions on how to address them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Task 7 - 1.0 points] Report\n",
    "\n",
    "Wrap up your experiment in a short report (up to 2 pages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Instructions\n",
    "\n",
    "* Use the NLP course report template.\n",
    "* Summarize each task in the report following the provided template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Recommendations\n",
    "\n",
    "The report is not a copy-paste of graphs, tables, and command outputs.\n",
    "\n",
    "* Summarize classification performance in Table format.\n",
    "* **Do not** report command outputs or screenshots.\n",
    "* Report learning curves in Figure format.\n",
    "* The error analysis section should summarize your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Submission\n",
    "\n",
    "* **Submit** your report in PDF format.\n",
    "* **Submit** your python notebook.\n",
    "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
    "* You can upload **model weights** in a cloud repository and report the link in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FAQ\n",
    "\n",
    "Please check this frequently asked questions before contacting us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Trainable Embeddings\n",
    "\n",
    "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model architecture\n",
    "\n",
    "You **should not** change the architecture of a model (i.e., its layers).\n",
    "\n",
    "However, you are **free** to play with their hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Neural Libraries\n",
    "\n",
    "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Keras TimeDistributed Dense layer\n",
    "\n",
    "If you are using Keras, we recommend wrapping the final Dense layer with `TimeDistributed`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Error Analysis\n",
    "\n",
    "Some topics for discussion include:\n",
    "   * Model performance on most/less frequent classes.\n",
    "   * Precision/Recall curves.\n",
    "   * Confusion matrices.\n",
    "   * Specific misclassified samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Punctuation\n",
    "\n",
    "**Do not** remove punctuation from documents since it may be helpful to the model.\n",
    "\n",
    "You should **ignore** it during metrics computation.\n",
    "\n",
    "If you are curious, you can run additional experiments to verify the impact of removing punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
