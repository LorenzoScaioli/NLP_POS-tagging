{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
        "\n",
        "**Keywords**: POS tagging, Sequence labelling, RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU8u6PyGerJ1"
      },
      "source": [
        "\n",
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "* Eleonora Mancini -> e.mancini@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn5lqLjaerJ2"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "You are tasked to address the task of POS tagging.\n",
        "\n",
        "<center>\n",
        "    <img src=\"images/pos_tagging.png\" alt=\"POS tagging\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl85WY79erJ2"
      },
      "source": [
        "# [Task 1 - 0.5 points] Corpus\n",
        "\n",
        "You are going to work with the [Penn TreeBank corpus](https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip).\n",
        "\n",
        "**Ignore** the numeric value in the third column, use **only** the words/symbols and their POS label.\n",
        "\n",
        "### Example\n",
        "\n",
        "```Pierre\tNNP\t2\n",
        "Vinken\tNNP\t8\n",
        ",\t,\t2\n",
        "61\tCD\t5\n",
        "years\tNNS\t6\n",
        "old\tJJ\t2\n",
        ",\t,\t2\n",
        "will\tMD\t0\n",
        "join\tVB\t8\n",
        "the\tDT\t11\n",
        "board\tNN\t9\n",
        "as\tIN\t9\n",
        "a\tDT\t15\n",
        "nonexecutive\tJJ\t15\n",
        "director\tNN\t12\n",
        "Nov.\tNNP\t9\n",
        "29\tCD\t16\n",
        ".\t.\t8\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DBSDHSeerJ3"
      },
      "source": [
        "### Splits\n",
        "\n",
        "The corpus contains 200 documents.\n",
        "\n",
        "   * **Train**: Documents 1-100\n",
        "   * **Validation**: Documents 101-150\n",
        "   * **Test**: Documents 151-199"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBhINLEaerJ3"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Download** the corpus.\n",
        "* **Encode** the corpus into a pandas.DataFrame object.\n",
        "* **Split** it in training, validation, and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azUjXF08erJ4"
      },
      "source": [
        "#### Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp4Q3iL6erJ4"
      },
      "source": [
        "#### Out of Vocabulary (OOV) words in training set\n",
        "We see words in the training set that are not alredy embedded through Glove (50) model, in addition we define the set oov_terms with all those words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:32.878447Z",
          "iopub.status.busy": "2023-11-20T17:28:32.878004Z",
          "iopub.status.idle": "2023-11-20T17:28:33.261992Z",
          "shell.execute_reply": "2023-11-20T17:28:33.261143Z",
          "shell.execute_reply.started": "2023-11-20T17:28:32.878414Z"
        },
        "id": "geRWC2XxerJ4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# file management\n",
        "import sys\n",
        "import shutil\n",
        "import urllib\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# dataframe management\n",
        "import pandas as pd\n",
        "\n",
        "# data manipulation\n",
        "import numpy as np\n",
        "\n",
        "# for readability\n",
        "from typing import Iterable\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_vPMgMyerJ6"
      },
      "source": [
        "#### Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:33.264066Z",
          "iopub.status.busy": "2023-11-20T17:28:33.263670Z",
          "iopub.status.idle": "2023-11-20T17:28:33.273576Z",
          "shell.execute_reply": "2023-11-20T17:28:33.272666Z",
          "shell.execute_reply.started": "2023-11-20T17:28:33.264039Z"
        },
        "id": "5AHbyJvIerJ6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "\n",
        "def download_url(download_path: Path, url: str):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=download_path, reporthook=t.update_to)\n",
        "\n",
        "\n",
        "def download_dataset(download_path: Path, url: str):\n",
        "    print(\"Downloading dataset...\")\n",
        "    download_url(url=url, download_path=download_path)\n",
        "    print(\"Download complete!\")\n",
        "\n",
        "def extract_dataset(download_path: Path, extract_path: Path):\n",
        "    print(\"Extracting dataset... (it may take a while...)\")\n",
        "\n",
        "    with zipfile.ZipFile(download_path) as loaded_tar:\n",
        "        loaded_tar.extractall(path=extract_path, pwd=None)\n",
        "    print(\"Extraction completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:33.274952Z",
          "iopub.status.busy": "2023-11-20T17:28:33.274676Z",
          "iopub.status.idle": "2023-11-20T17:28:33.538381Z",
          "shell.execute_reply": "2023-11-20T17:28:33.537434Z",
          "shell.execute_reply.started": "2023-11-20T17:28:33.274927Z"
        },
        "id": "TjwV2cFTerJ7",
        "outputId": "175480eb-a27c-4538-fafb-adbd1f8f6fa0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current work directory: /content\n"
          ]
        }
      ],
      "source": [
        "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
        "dataset_name = \"dependency_treebank\"\n",
        "\n",
        "print(f\"Current work directory: {Path.cwd()}\")\n",
        "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
        "\n",
        "if not dataset_folder.exists():\n",
        "    dataset_folder.mkdir(parents=True)\n",
        "\n",
        "dataset_tar_path = dataset_folder.joinpath(\"dependency_treebank.zip\")\n",
        "dataset_path = dataset_folder.joinpath(dataset_name)\n",
        "\n",
        "if not dataset_tar_path.exists():\n",
        "    download_dataset(dataset_tar_path, url)\n",
        "\n",
        "if not dataset_path.exists():\n",
        "    extract_dataset(dataset_tar_path, dataset_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DVROHUherJ9"
      },
      "source": [
        "#### Encode and Split\n",
        "\n",
        "The aim of the code below is to find a way to create a dataframe starting from all the files downloaded before.\n",
        "For every downloaded file, we check the number through the function find_number(), we decide if it belongs to train, validation or test given that number, we then split it into rows to get the word and the POS and to check where a phrase ends. Given all this informations we can create a list whose columns are:\n",
        "1. num_file: the number of the file\n",
        "2. phrase_id: the id of the phrase contained in a file\n",
        "3. text: the text that has to be analyzed\n",
        "4. pos: the tag assigned to the text\n",
        "5. split: the split to which the text belongs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:33.540010Z",
          "iopub.status.busy": "2023-11-20T17:28:33.539685Z",
          "iopub.status.idle": "2023-11-20T17:28:33.545402Z",
          "shell.execute_reply": "2023-11-20T17:28:33.544379Z",
          "shell.execute_reply.started": "2023-11-20T17:28:33.539983Z"
        },
        "id": "OaiKoGb3erJ9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def find_number(string):\n",
        "    \"\"\"\n",
        "    This function finds the number written in a string.\n",
        "    \"\"\"\n",
        "    return re.findall(r'\\d+', string)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:33.549435Z",
          "iopub.status.busy": "2023-11-20T17:28:33.548953Z",
          "iopub.status.idle": "2023-11-20T17:28:33.785708Z",
          "shell.execute_reply": "2023-11-20T17:28:33.784627Z",
          "shell.execute_reply.started": "2023-11-20T17:28:33.549399Z"
        },
        "id": "TTtotZNkerJ9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dataframe_rows = []\n",
        "id = 0\n",
        "\n",
        "folder = dataset_folder.joinpath(dataset_name)\n",
        "for file_path in folder.glob('*.dp'):\n",
        "    num_file = int(find_number(file_path.name)[0])\n",
        "    id = 1\n",
        "\n",
        "    with file_path.open(mode='r', encoding='utf-8') as text_file:\n",
        "\n",
        "        if num_file < 101:\n",
        "            split = \"train\"\n",
        "        elif num_file >= 101 and num_file < 151:\n",
        "            split = \"validation\"\n",
        "        else:\n",
        "            split = \"test\"\n",
        "\n",
        "        for row in text_file.readlines():\n",
        "            if row=='\\n' or row=='':\n",
        "                id += 1\n",
        "\n",
        "            else:\n",
        "                text, pos, _ = row.split('\\t')\n",
        "\n",
        "                dataframe_row = {\n",
        "                    \"num_file\": num_file,\n",
        "                    \"phrase_id\": str(num_file) + \"_\" + str(id),\n",
        "                    \"text\": text,\n",
        "                    \"pos\": pos,\n",
        "                    \"split\": split\n",
        "                }\n",
        "\n",
        "                dataframe_rows.append(dataframe_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:33.787673Z",
          "iopub.status.busy": "2023-11-20T17:28:33.787248Z",
          "iopub.status.idle": "2023-11-20T17:28:34.014786Z",
          "shell.execute_reply": "2023-11-20T17:28:34.013688Z",
          "shell.execute_reply.started": "2023-11-20T17:28:33.787633Z"
        },
        "id": "O01Zu0lAerJ-",
        "outputId": "2f4f412f-6b18-4fce-d819-ef35d013df2d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dcaab13d-2eb1-442a-aa57-92b9d6c6b3ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_file</th>\n",
              "      <th>phrase_id</th>\n",
              "      <th>text</th>\n",
              "      <th>pos</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>Rep.</td>\n",
              "      <td>NNP</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>John</td>\n",
              "      <td>NNP</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>Dingell</td>\n",
              "      <td>NNP</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>an</td>\n",
              "      <td>DT</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>important</td>\n",
              "      <td>JJ</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>sponsor</td>\n",
              "      <td>NN</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>President</td>\n",
              "      <td>NNP</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>Bush</td>\n",
              "      <td>NNP</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>'s</td>\n",
              "      <td>POS</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>clean-air</td>\n",
              "      <td>JJ</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>bill</td>\n",
              "      <td>NN</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>plans</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>unveil</td>\n",
              "      <td>VB</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>surprise</td>\n",
              "      <td>NN</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>146</td>\n",
              "      <td>146_1</td>\n",
              "      <td>proposal</td>\n",
              "      <td>NN</td>\n",
              "      <td>validation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcaab13d-2eb1-442a-aa57-92b9d6c6b3ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dcaab13d-2eb1-442a-aa57-92b9d6c6b3ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dcaab13d-2eb1-442a-aa57-92b9d6c6b3ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fbec9be4-f60a-4492-a848-999a6af24c65\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fbec9be4-f60a-4492-a848-999a6af24c65')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fbec9be4-f60a-4492-a848-999a6af24c65 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    num_file phrase_id       text  pos       split\n",
              "0        146     146_1       Rep.  NNP  validation\n",
              "1        146     146_1       John  NNP  validation\n",
              "2        146     146_1    Dingell  NNP  validation\n",
              "3        146     146_1          ,    ,  validation\n",
              "4        146     146_1         an   DT  validation\n",
              "5        146     146_1  important   JJ  validation\n",
              "6        146     146_1    sponsor   NN  validation\n",
              "7        146     146_1         of   IN  validation\n",
              "8        146     146_1  President  NNP  validation\n",
              "9        146     146_1       Bush  NNP  validation\n",
              "10       146     146_1         's  POS  validation\n",
              "11       146     146_1  clean-air   JJ  validation\n",
              "12       146     146_1       bill   NN  validation\n",
              "13       146     146_1          ,    ,  validation\n",
              "14       146     146_1      plans  VBZ  validation\n",
              "15       146     146_1         to   TO  validation\n",
              "16       146     146_1     unveil   VB  validation\n",
              "17       146     146_1          a   DT  validation\n",
              "18       146     146_1   surprise   NN  validation\n",
              "19       146     146_1   proposal   NN  validation"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(dataframe_rows)\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56t_8upaerJ-"
      },
      "source": [
        "# [Task 2 - 0.5 points] Text encoding\n",
        "\n",
        "To train a neural POS tagger, you first need to encode text into numerical format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IpIpTPoerJ_"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Embed words using **GloVe embeddings**.\n",
        "* You are **free** to pick any embedding dimension.\n",
        "* [Optional] You are free to experiment with text pre-processing: **make sure you do not delete any token!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:34.016375Z",
          "iopub.status.busy": "2023-11-20T17:28:34.016029Z",
          "iopub.status.idle": "2023-11-20T17:28:34.021311Z",
          "shell.execute_reply": "2023-11-20T17:28:34.020216Z",
          "shell.execute_reply.started": "2023-11-20T17:28:34.016345Z"
        },
        "id": "hpVTQ-o6erJ_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# typing\n",
        "from typing import List, Callable, Dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sPpHwhHerJ_"
      },
      "source": [
        "#### Text pre-processing\n",
        "In the code below we pre-processed the df dataframe in order to reduce the number of different words. Our text pre-processing consist just in lowering the text of words. <br>\n",
        "**NB: should we add somenthing to the pre processing?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:34.023641Z",
          "iopub.status.busy": "2023-11-20T17:28:34.023094Z",
          "iopub.status.idle": "2023-11-20T17:28:35.756398Z",
          "shell.execute_reply": "2023-11-20T17:28:35.755525Z",
          "shell.execute_reply.started": "2023-11-20T17:28:34.023553Z"
        },
        "id": "_BBGJLkeerJ_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from functools import reduce\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:35.757918Z",
          "iopub.status.busy": "2023-11-20T17:28:35.757604Z",
          "iopub.status.idle": "2023-11-20T17:28:35.762885Z",
          "shell.execute_reply": "2023-11-20T17:28:35.761863Z",
          "shell.execute_reply.started": "2023-11-20T17:28:35.757892Z"
        },
        "id": "59cctQmxerKA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def lower(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Transforms given text to lower case.\n",
        "    \"\"\"\n",
        "    return text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:35.764417Z",
          "iopub.status.busy": "2023-11-20T17:28:35.764075Z",
          "iopub.status.idle": "2023-11-20T17:28:35.775830Z",
          "shell.execute_reply": "2023-11-20T17:28:35.774984Z",
          "shell.execute_reply.started": "2023-11-20T17:28:35.764366Z"
        },
        "id": "jSzHoq7BerKA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "PREPROCESSING_PIPELINE = [\n",
        "                          lower\n",
        "                          ]\n",
        "\n",
        "def text_prepare(text: str,\n",
        "                 filter_methods: List[Callable[[str], str]] = None) -> str:\n",
        "    \"\"\"\n",
        "    Applies a list of pre-processing functions in sequence (reduce).\n",
        "    Note that the order is important here!\n",
        "    \"\"\"\n",
        "    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n",
        "    return reduce(lambda txt, f: f(txt), filter_methods, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:35.777282Z",
          "iopub.status.busy": "2023-11-20T17:28:35.776990Z",
          "iopub.status.idle": "2023-11-20T17:28:35.903065Z",
          "shell.execute_reply": "2023-11-20T17:28:35.902113Z",
          "shell.execute_reply.started": "2023-11-20T17:28:35.777257Z"
        },
        "id": "MQi5fld5erKA",
        "outputId": "600a7c32-ff7c-44b0-fb89-68a98bfa8fe3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-processing text...\n",
            "\n",
            "[Debug] Before:\n",
            "Rep.\n",
            "\n",
            "[Debug] After:\n",
            "rep.\n",
            "\n",
            "Pre-processing completed!\n"
          ]
        }
      ],
      "source": [
        "print('Pre-processing text...')\n",
        "\n",
        "print()\n",
        "print(f'[Debug] Before:\\n{df.text.values[0]}')\n",
        "print()\n",
        "\n",
        "# Replace each sentence with its pre-processed version\n",
        "df['text'] = df['text'].apply(lambda txt: text_prepare(txt))\n",
        "\n",
        "print(f'[Debug] After:\\n{df.text.values[0]}')\n",
        "print()\n",
        "\n",
        "print(\"Pre-processing completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h47lVPfierKA"
      },
      "source": [
        "#### Vocabulary creation for training set\n",
        "We define a vocabulary for the training set assigning to each word a random index, the building_vocabulary function returns a list containing:<br>\n",
        "- word vocabulary: vocabulary index to word\n",
        "- inverse word vocabulary: word to vocabulary index\n",
        "- word listing: set of unique terms that build up the vocabulary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:35.905088Z",
          "iopub.status.busy": "2023-11-20T17:28:35.904709Z",
          "iopub.status.idle": "2023-11-20T17:28:35.978078Z",
          "shell.execute_reply": "2023-11-20T17:28:35.977203Z",
          "shell.execute_reply.started": "2023-11-20T17:28:35.905052Z"
        },
        "id": "1sR32eMrerKB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_train = df[df['split']=='train']\n",
        "df_val = df[df['split']=='validation']\n",
        "df_test = df[df['split']=='test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc3eQ6AderKB"
      },
      "source": [
        "#### GloVe embeddings (50)\n",
        "Download GloVe 50 embedding where most of the words are alredy embedded in an embedding model that associate each word to a vector of dimension 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:35.980050Z",
          "iopub.status.busy": "2023-11-20T17:28:35.979409Z",
          "iopub.status.idle": "2023-11-20T17:28:35.984430Z",
          "shell.execute_reply": "2023-11-20T17:28:35.983403Z",
          "shell.execute_reply.started": "2023-11-20T17:28:35.980013Z"
        },
        "id": "nIW7yyFgerKB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# !pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:35.988166Z",
          "iopub.status.busy": "2023-11-20T17:28:35.987892Z",
          "iopub.status.idle": "2023-11-20T17:28:44.567366Z",
          "shell.execute_reply": "2023-11-20T17:28:44.566483Z",
          "shell.execute_reply.started": "2023-11-20T17:28:35.988142Z"
        },
        "id": "stvoRolverKB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "\n",
        "def load_embedding_model(model_type: str,\n",
        "                         embedding_dimension: int = 50) -> gensim.models.keyedvectors.KeyedVectors:\n",
        "    \"\"\"\n",
        "    Loads a pre-trained word embedding model via gensim library.\n",
        "\n",
        "    :param model_type: name of the word embedding model to load.\n",
        "    :param embedding_dimension: size of the embedding space to consider\n",
        "\n",
        "    :return\n",
        "        - pre-trained word embedding model (gensim KeyedVectors object)\n",
        "    \"\"\"\n",
        "    download_path = \"\"\n",
        "\n",
        "    if model_type.strip().lower() == 'glove':\n",
        "        download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
        "    else:\n",
        "        raise AttributeError(\"Unsupported embedding model type! Available one: glove\")\n",
        "\n",
        "    try:\n",
        "        emb_model = gloader.load(download_path)\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
        "        print(\"Glove: 50, 100, 200, 300\")\n",
        "        raise e\n",
        "\n",
        "    return emb_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:28:44.568939Z",
          "iopub.status.busy": "2023-11-20T17:28:44.568460Z",
          "iopub.status.idle": "2023-11-20T17:29:17.221564Z",
          "shell.execute_reply": "2023-11-20T17:29:17.220762Z",
          "shell.execute_reply.started": "2023-11-20T17:28:44.568913Z"
        },
        "id": "HRmCZlDYerKC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "embedding_dim = 50\n",
        "\n",
        "embedding_model = load_embedding_model(model_type=\"glove\",\n",
        "                                       embedding_dimension=embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:29:17.223031Z",
          "iopub.status.busy": "2023-11-20T17:29:17.222695Z",
          "iopub.status.idle": "2023-11-20T17:29:17.985318Z",
          "shell.execute_reply": "2023-11-20T17:29:17.984381Z",
          "shell.execute_reply.started": "2023-11-20T17:29:17.223003Z"
        },
        "id": "znNezbjgerKC",
        "outputId": "c98c6eda-3520-46c2-8574-0b6aae598a92",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding matrix shape: (400001, 50)\n"
          ]
        }
      ],
      "source": [
        "vocab = {} # word to idx\n",
        "embedding_matrix_glove = np.zeros((400001, embedding_dim))\n",
        "\n",
        "for i in range(0, 400000):\n",
        "    vocab[embedding_model.index_to_key[i]] = i+1\n",
        "    embedding_matrix_glove[i+1] = embedding_model.vectors[i]\n",
        "\n",
        "print(f'Embedding matrix shape: {embedding_matrix_glove.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:29:17.986972Z",
          "iopub.status.busy": "2023-11-20T17:29:17.986587Z",
          "iopub.status.idle": "2023-11-20T17:29:17.992578Z",
          "shell.execute_reply": "2023-11-20T17:29:17.991698Z",
          "shell.execute_reply.started": "2023-11-20T17:29:17.986945Z"
        },
        "id": "D67KXftCerKC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def check_OOV_terms(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
        "                    word_listing: List[str]):\n",
        "    \"\"\"\n",
        "    Checks differences between pre-trained embedding model vocabulary\n",
        "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
        "\n",
        "    :param embedding_model: pre-trained word embedding model (gensim wrapper)\n",
        "    :param word_listing: dataset specific vocabulary (list)\n",
        "\n",
        "    :return\n",
        "        - list of OOV terms\n",
        "    \"\"\"\n",
        "    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
        "    oov = set(word_listing).difference(embedding_vocabulary)\n",
        "    return list(oov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:29:17.993859Z",
          "iopub.status.busy": "2023-11-20T17:29:17.993564Z",
          "iopub.status.idle": "2023-11-20T17:29:18.082231Z",
          "shell.execute_reply": "2023-11-20T17:29:18.081280Z",
          "shell.execute_reply.started": "2023-11-20T17:29:17.993835Z"
        },
        "id": "choHIOBUerKD",
        "outputId": "33274b79-2c1d-4bfa-c001-ac5e5943d171",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total OOV terms: 359 (4.85%)\n"
          ]
        }
      ],
      "source": [
        "word_listing = set(df_train['text'])\n",
        "oov_terms = check_OOV_terms(embedding_model, word_listing)\n",
        "oov_percentage = float(len(oov_terms)) * 100 / len(word_listing)\n",
        "print(f\"Total OOV terms: {len(oov_terms)} ({oov_percentage:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1zIe3RWerKD"
      },
      "source": [
        "Here we add the OOV in the train set to the vocabulary and the embedded matrix </br>\n",
        "*NB: maybe is better to define the OOV as the mean of all the other word, link for report (https://stackoverflow.com/questions/49239941/what-is-unk-in-the-pretrained-glove-vector-files-e-g-glove-6b-50d-txt)* <br>\n",
        "Our embedding matrix has the following columns:\n",
        "- column 0 is all zeros, represents the embedding vector for padding\n",
        "- columns 1 to 400001 are the embedding vectors for the words in GloVe\n",
        "- columns 400002 to 400360 are the embedding vectors for the words OOV in the training set (random vector)\n",
        "- column 400361 is the embedding vector for the words OOV in the final vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:29:18.083837Z",
          "iopub.status.busy": "2023-11-20T17:29:18.083544Z",
          "iopub.status.idle": "2023-11-20T17:29:38.116881Z",
          "shell.execute_reply": "2023-11-20T17:29:38.115940Z",
          "shell.execute_reply.started": "2023-11-20T17:29:18.083804Z"
        },
        "id": "3YIEwC86erKD",
        "outputId": "d2d2e402-e67d-490b-9c10-a0d1078e449d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400361\n",
            "New embedding matrix size: (400361, 50)\n"
          ]
        }
      ],
      "source": [
        "for word in oov_terms:\n",
        "    vocab[word] = 400002 + oov_terms.index(word)\n",
        "    embedding_matrix_glove = np.append(embedding_matrix_glove, np.random.uniform(-0.25, 0.25, 50).reshape(1, 50), axis=0)\n",
        "\n",
        "vocab['[OOV]'] = len(vocab) + 1\n",
        "average_oov = np.mean(embedding_matrix_glove, axis=0)\n",
        "embedding_matrix = np.append(embedding_matrix_glove, average_oov.reshape(1, 50), axis=0)\n",
        "\n",
        "vocab['[PAD]'] = 0\n",
        "\n",
        "print(len(vocab))\n",
        "print(f\"New embedding matrix size: {embedding_matrix.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_5YoZOserKE"
      },
      "source": [
        "#### Embedding for training set\n",
        "We create the embedding matrix for all the training set:\n",
        "- using GloVe embeddings for alredy known words\n",
        "- assigning to each OOV word a random value.\n",
        "\n",
        "**NB: maybe instead of random we can define OOV with the mean of its neighbour word embeddings (tutorial 2)** <br>\n",
        "**NB: we can even add all embedding in GloVe to the embedding matrix, even if they are not in train set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDJl1QCmerKE"
      },
      "source": [
        "# [Task 3 - 1.0 points] Model definition\n",
        "\n",
        "You are now tasked to define your neural POS tagger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-atMXterKE"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Baseline**: implement a Bidirectional LSTM with a Dense layer on top.\n",
        "* You are **free** to experiment with hyper-parameters to define the baseline model.\n",
        "\n",
        "* **Model 1**: add an additional LSTM layer to the Baseline model.\n",
        "* **Model 2**: add an additional Dense layer to the Baseline model.\n",
        "\n",
        "* **Do not mix Model 1 and Model 2**. Each model has its own instructions.\n",
        "\n",
        "**Note**: if a document contains many tokens, you are **free** to split them into chunks or sentences to define your mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:33:55.859861Z",
          "iopub.status.busy": "2023-11-20T17:33:55.858959Z",
          "iopub.status.idle": "2023-11-20T17:33:55.874207Z",
          "shell.execute_reply": "2023-11-20T17:33:55.873349Z",
          "shell.execute_reply.started": "2023-11-20T17:33:55.859823Z"
        },
        "id": "-zKpiu-4erKE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "list_of_pos = list(set(df_train['pos']))\n",
        "\n",
        "def pos_to_int(string):\n",
        "    if string == '[PAD]':\n",
        "        return np.zeros((45,), dtype=int).tolist()\n",
        "    length = len(list_of_pos)\n",
        "    for i in range(length):\n",
        "        if list_of_pos[i] == string:\n",
        "            return [1 if j == i else 0 for j in range(length)]\n",
        "\n",
        "def int_to_pos(phrase):\n",
        "    return [list_of_pos[np.argmax(phrase[w])] if max(phrase[w]) != 0 else '[PAD]' for w in range(pad)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:33:56.238618Z",
          "iopub.status.busy": "2023-11-20T17:33:56.238254Z",
          "iopub.status.idle": "2023-11-20T17:33:56.243674Z",
          "shell.execute_reply": "2023-11-20T17:33:56.242616Z",
          "shell.execute_reply.started": "2023-11-20T17:33:56.238589Z"
        },
        "id": "v0C7RLs8erKR",
        "outputId": "b4ab9d17-a772-44fd-d44e-8f01ff275125",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(pos_to_int('.'))\n",
        "print(pos_to_int('[PAD]'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:33:56.681492Z",
          "iopub.status.busy": "2023-11-20T17:33:56.680802Z",
          "iopub.status.idle": "2023-11-20T17:33:56.686037Z",
          "shell.execute_reply": "2023-11-20T17:33:56.685239Z",
          "shell.execute_reply.started": "2023-11-20T17:33:56.681458Z"
        },
        "id": "YI2tX8E_jv18",
        "outputId": "0fe9e512-8410-4283-ec0f-3bfdd433cfa0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "45 ['.', 'RBR', 'UH', '``', 'PRP$', 'TO', 'WP', ',', 'JJ', 'NNS', 'WRB', 'WDT', 'IN', 'PDT', 'SYM', 'MD', 'LS', '-RRB-', 'VB', 'PRP', '$', 'VBG', 'NNPS', '-LRB-', '#', 'RP', 'WP$', 'VBP', 'RBS', 'EX', 'JJS', 'CC', 'VBZ', 'CD', 'DT', \"''\", 'POS', 'VBD', ':', 'RB', 'NNP', 'JJR', 'FW', 'NN', 'VBN']\n"
          ]
        }
      ],
      "source": [
        "print(len(list_of_pos), list_of_pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pc8WXOoerKS"
      },
      "source": [
        "#### Baseline\n",
        "**NB: reference slides 08 pag 38** <br>\n",
        "https://analyticsindiamag.com/complete-guide-to-bidirectional-lstm-with-python-codes/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:34:18.348890Z",
          "iopub.status.busy": "2023-11-20T17:34:18.348168Z",
          "iopub.status.idle": "2023-11-20T17:34:35.583647Z",
          "shell.execute_reply": "2023-11-20T17:34:35.582521Z",
          "shell.execute_reply.started": "2023-11-20T17:34:18.348854Z"
        },
        "id": "GVhN0_EzerKS",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ! pip install tensorflow\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras as keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:36:38.089888Z",
          "iopub.status.busy": "2023-11-20T17:36:38.088830Z",
          "iopub.status.idle": "2023-11-20T17:36:38.094485Z",
          "shell.execute_reply": "2023-11-20T17:36:38.093644Z",
          "shell.execute_reply.started": "2023-11-20T17:36:38.089851Z"
        },
        "id": "WtAw13JjerKT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "GloVe_dim = 50 # GloVe embedding\n",
        "units_bi = 64\n",
        "\n",
        "n_unique_words = len(vocab) # input and output layer\n",
        "outputs_dim = len(list_of_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:36:46.505878Z",
          "iopub.status.busy": "2023-11-20T17:36:46.505146Z",
          "iopub.status.idle": "2023-11-20T17:36:52.733684Z",
          "shell.execute_reply": "2023-11-20T17:36:52.732727Z",
          "shell.execute_reply.started": "2023-11-20T17:36:46.505845Z"
        },
        "id": "hyw7dSlVerKT",
        "outputId": "ba67a008-1f23-4f3b-efce-c54b762bb5e8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 50)          20018050  \n",
            "                                                                 \n",
            " masking_3 (Masking)         (None, None, 50)          0         \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirecti  (None, None, 128)         58880     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDi  (None, None, 45)          5805      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20082735 (76.61 MB)\n",
            "Trainable params: 64685 (252.68 KB)\n",
            "Non-trainable params: 20018050 (76.36 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "baseline = tf.keras.Sequential(name='baseline')\n",
        "\n",
        "baseline.add(layers.Embedding(n_unique_words, GloVe_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix), mask_zero=True, trainable=False))\n",
        "baseline.add(layers.Masking(mask_value=0))\n",
        "baseline.add(layers.Bidirectional(layers.LSTM(units_bi, activation='relu', return_sequences=True)))\n",
        "baseline.add(layers.TimeDistributed(layers.Dense(outputs_dim, activation='softmax')))\n",
        "\n",
        "baseline.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp2BrTbderKT"
      },
      "source": [
        "#### Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:37:03.349784Z",
          "iopub.status.busy": "2023-11-20T17:37:03.349398Z",
          "iopub.status.idle": "2023-11-20T17:37:03.973614Z",
          "shell.execute_reply": "2023-11-20T17:37:03.972655Z",
          "shell.execute_reply.started": "2023-11-20T17:37:03.349753Z"
        },
        "id": "CBDSLT6MerKT",
        "outputId": "5ffbc1d6-a1f6-48fd-def7-77f6b00df142",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 50)          20018050  \n",
            "                                                                 \n",
            " masking_4 (Masking)         (None, None, 50)          0         \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirecti  (None, None, 128)         58880     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirecti  (None, None, 128)         98816     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDi  (None, None, 45)          5805      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20181551 (76.99 MB)\n",
            "Trainable params: 163501 (638.68 KB)\n",
            "Non-trainable params: 20018050 (76.36 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1 = tf.keras.Sequential(name='Model_1')\n",
        "\n",
        "model_1.add(layers.Embedding(n_unique_words, GloVe_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix), mask_zero=True, trainable=False))\n",
        "model_1.add(layers.Masking(mask_value=0))\n",
        "model_1.add(layers.Bidirectional(layers.LSTM(units_bi, activation='relu', return_sequences=True)))\n",
        "model_1.add(layers.Bidirectional(layers.LSTM(units_bi, activation='relu', return_sequences=True)))\n",
        "model_1.add(layers.TimeDistributed(layers.Dense(outputs_dim, activation='softmax')))\n",
        "\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PX07mrgerKU"
      },
      "source": [
        "#### Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:38:25.965161Z",
          "iopub.status.busy": "2023-11-20T17:38:25.964404Z",
          "iopub.status.idle": "2023-11-20T17:38:25.969162Z",
          "shell.execute_reply": "2023-11-20T17:38:25.968259Z",
          "shell.execute_reply.started": "2023-11-20T17:38:25.965129Z"
        },
        "id": "z8kOFO33erKU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "units_dense = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T17:38:26.347478Z",
          "iopub.status.busy": "2023-11-20T17:38:26.346994Z",
          "iopub.status.idle": "2023-11-20T17:38:26.793587Z",
          "shell.execute_reply": "2023-11-20T17:38:26.792635Z",
          "shell.execute_reply.started": "2023-11-20T17:38:26.347442Z"
        },
        "id": "bVOOuVFOerKU",
        "outputId": "20c5f888-846c-48ae-c533-a9b406a3d28e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, None, 50)          20018050  \n",
            "                                                                 \n",
            " masking_5 (Masking)         (None, None, 50)          0         \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, None, 128)         58880     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDi  (None, None, 64)          8256      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDi  (None, None, 45)          2925      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20088111 (76.63 MB)\n",
            "Trainable params: 70061 (273.68 KB)\n",
            "Non-trainable params: 20018050 (76.36 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_2 = tf.keras.Sequential(name='Model_2')\n",
        "\n",
        "model_2.add(layers.Embedding(n_unique_words, GloVe_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix), mask_zero=True, trainable=False))\n",
        "model_2.add(layers.Masking(mask_value=0))\n",
        "model_2.add(layers.Bidirectional(layers.LSTM(units_bi, activation='relu', return_sequences=True)))\n",
        "model_2.add(layers.TimeDistributed(layers.Dense(units_dense, activation='softmax')))\n",
        "model_2.add(layers.TimeDistributed(layers.Dense(outputs_dim, activation='softmax')))\n",
        "\n",
        "\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bUJsobderKV"
      },
      "source": [
        "#### try models\n",
        "\n",
        "https://medium.com/analytics-vidhya/author-multi-class-text-classification-using-bidirectional-lstm-keras-c9a533a1cc4a\n",
        "an example of a bi LSTM implementation with padding <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:39:52.402377Z",
          "iopub.status.busy": "2023-11-20T17:39:52.401596Z",
          "iopub.status.idle": "2023-11-20T17:39:52.407102Z",
          "shell.execute_reply": "2023-11-20T17:39:52.406241Z",
          "shell.execute_reply.started": "2023-11-20T17:39:52.402342Z"
        },
        "id": "H1-H7HKierKV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def assign_idx(word):\n",
        "    try:\n",
        "        idx = vocab[word]\n",
        "    except(KeyError):\n",
        "        idx = vocab['[OOV]']\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T17:39:54.056602Z",
          "iopub.status.busy": "2023-11-20T17:39:54.055647Z",
          "iopub.status.idle": "2023-11-20T17:39:54.060227Z",
          "shell.execute_reply": "2023-11-20T17:39:54.059406Z",
          "shell.execute_reply.started": "2023-11-20T17:39:54.056567Z"
        },
        "id": "Znc_7hdperKV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# df_train_reduction = df_train.loc[df_train['num_file'] <= 50]\n",
        "# df_val_reduction = df_val.loc[df_val['num_file'] <= 115]\n",
        "# df_test_reduction = df_test.loc[df_test['num_file'] <= 165]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T18:49:24.639966Z",
          "iopub.status.busy": "2023-11-20T18:49:24.639562Z",
          "iopub.status.idle": "2023-11-20T18:50:13.110727Z",
          "shell.execute_reply": "2023-11-20T18:50:13.109704Z",
          "shell.execute_reply.started": "2023-11-20T18:49:24.639934Z"
        },
        "id": "s7cq2w3werKV",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "x_train = [ [assign_idx(word) for word in df_train[df_train['phrase_id']==nr_phrase]['text']] for nr_phrase in set(df_train['phrase_id']) ]\n",
        "x_val   = [ [assign_idx(word) for word in df_val[df_val['phrase_id']==nr_phrase]['text']] for nr_phrase in set(df_val['phrase_id']) ]\n",
        "x_test   = [ [assign_idx(word) for word in df_test[df_test['phrase_id']==nr_phrase]['text']] for nr_phrase in set(df_test['phrase_id']) ]\n",
        "\n",
        "y_train = [ [pos_to_int(pos) for pos in df_train[df_train['phrase_id']==nr_phrase]['pos']] for nr_phrase in set(df_train['phrase_id']) ]\n",
        "y_val   = [ [pos_to_int(pos) for pos in df_val[df_val['phrase_id']==nr_phrase]['pos']] for nr_phrase in set(df_val['phrase_id']) ]\n",
        "y_test   = [ [pos_to_int(pos) for pos in df_test[df_test['phrase_id']==nr_phrase]['pos']] for nr_phrase in set(df_test['phrase_id']) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T18:50:13.112888Z",
          "iopub.status.busy": "2023-11-20T18:50:13.112544Z",
          "iopub.status.idle": "2023-11-20T18:50:21.752690Z",
          "shell.execute_reply": "2023-11-20T18:50:21.751864Z",
          "shell.execute_reply.started": "2023-11-20T18:50:13.112859Z"
        },
        "id": "oLAKfqJ0erKW",
        "outputId": "12693372-b6bc-46d7-e8b6-4651f32ff507",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The length of all phrases after padding will be  249\n"
          ]
        }
      ],
      "source": [
        "#In order to put the data data in data in the model we need to pad the array representing the words / pos\n",
        "\n",
        "pad = max(max([len(phrase) for phrase in x_train]), max([len(phrase) for phrase in x_val]), max([len(phrase) for phrase in x_test]))\n",
        "print(\"The length of all phrases after padding will be \", pad)\n",
        "\n",
        "x_train_pad = [phrase + np.zeros((pad-len(phrase),), dtype=int).tolist() for phrase in x_train]\n",
        "x_val_pad = [phrase + np.zeros((pad-len(phrase),), dtype=int).tolist() for phrase in x_val]\n",
        "x_test_pad = [phrase + np.zeros((pad-len(phrase),), dtype=int).tolist() for phrase in x_test]\n",
        "\n",
        "y_train_pad = [phrase + np.zeros((pad-len(phrase), 45)).tolist() for phrase in y_train]\n",
        "y_val_pad = [phrase + np.zeros((pad-len(phrase), 45)).tolist() for phrase in y_val]\n",
        "y_test_pad = [phrase + np.zeros((pad-len(phrase), 45)).tolist() for phrase in y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T18:50:21.776021Z",
          "iopub.status.busy": "2023-11-20T18:50:21.775654Z",
          "iopub.status.idle": "2023-11-20T18:50:21.787167Z",
          "shell.execute_reply": "2023-11-20T18:50:21.786412Z",
          "shell.execute_reply.started": "2023-11-20T18:50:21.775991Z"
        },
        "id": "9Plr2ULAhqWs",
        "outputId": "171f3337-6608-4ba8-9230-a0b87ec3eeaf",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1963 1299 652\n"
          ]
        }
      ],
      "source": [
        "print(len(x_train), len(x_val), len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bO0rnF4mm6Lz",
        "outputId": "3e26f30c-8548-497b-8d70-b4a20d427bdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24\n",
            "249\n",
            "[1, 21640, 6, 16350, 2309, 33, 288, 5, 466, 3126, 200, 183, 63, 2, 6, 1, 79607, 6, 400009, 2309, 169, 183, 63, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(len(x_train[0]))\n",
        "print(len(x_train_pad[0]))\n",
        "print(x_train_pad[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2A26JuUm8Sz",
        "outputId": "73ff9b11-8776-478d-a032-1aa88ce75ea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the perch and dolphin fields are expected to start producing early next year , and the seahorse and tarwhine fields later next year . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "['DT', 'NNP', 'CC', 'NNP', 'NNS', 'VBP', 'VBN', 'TO', 'VB', 'VBG', 'JJ', 'JJ', 'NN', ',', 'CC', 'DT', 'NNP', 'CC', 'NNP', 'NNS', 'JJ', 'JJ', 'NN', '.', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ],
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in vocab.items()])\n",
        "def decode_phrase(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "print(decode_phrase(x_train_pad[0]))\n",
        "print(int_to_pos(y_train_pad[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cQah6XJerKW"
      },
      "source": [
        "# [Task 4 - 1.0 points] Metrics\n",
        "\n",
        "Before training the models, you are tasked to define the evaluation metrics for comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELGz0EB5erKW"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Evaluate your models using macro F1-score, compute over **all** tokens.\n",
        "* **Concatenate** all tokens in a data split to compute the F1-score. (**Hint**: accumulate FP, TP, FN, TN iteratively)\n",
        "* **Do not consider punctuation and symbol classes** $\\rightarrow$ [What is punctuation?](https://en.wikipedia.org/wiki/English_punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qvrXuZVerKW"
      },
      "source": [
        "**Note**: What about OOV tokens?\n",
        "   * All the tokens in the **training** set that are not in GloVe are **not** considered as OOV\n",
        "   * For the remaining tokens (i.e., OOV in the validation and test sets), you have to assign them a **static** embedding.\n",
        "   * You are **free** to define the static embedding using any strategy (e.g., random, neighbourhood, etc...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "9rqWJlb_dGxN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "ignore_classes = ['[PAD]', '#', '``', '-RRB-', \"''\", '$', 'SYM', ':', '.', ',', '-LRB-']\n",
        "\n",
        "class MetricsCallback(Callback):\n",
        "    def __init__(self, x, y_true, ignore_classes=None):\n",
        "        super().__init__()\n",
        "        self.x = x\n",
        "        self.y_true = y_true\n",
        "        self.ignore_classes = ignore_classes if ignore_classes else []\n",
        "        self.metrics_dict = {}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_pred = self.model.predict(self.x)\n",
        "        y_true_pos = [int_to_pos(true) for true in self.y_true]\n",
        "        y_pred_pos = [int_to_pos(pred) for pred in y_pred]\n",
        "\n",
        "        exclude_indices = [i for i, tag in enumerate(y_true_pos) if tag in self.ignore_classes]\n",
        "        y_true_pos_clean = np.delete(y_true_pos, exclude_indices)\n",
        "        y_pred_pos_clean = np.delete(y_pred_pos, exclude_indices)\n",
        "\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            y_true_pos_clean, y_pred_pos_clean, average='macro', zero_division=1\n",
        "        )\n",
        "\n",
        "        accuracy = accuracy_score(y_true_pos_clean, y_pred_pos_clean)\n",
        "\n",
        "        self.metrics_dict['macro_f1'] = f1\n",
        "        self.metrics_dict['precision'] = precision\n",
        "        self.metrics_dict['recall'] = recall\n",
        "        self.metrics_dict['accuracy'] = accuracy\n",
        "\n",
        "        print(f\"Macro F1-Score: {f1:.4f} - Precision: {precision:.4f} - Recall: {recall:.4f} - Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGZS-c3TerKX"
      },
      "source": [
        "# [Task 5 - 1.0 points] Training and Evaluation\n",
        "\n",
        "You are now tasked to train and evaluate the Baseline, Model 1, and Model 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS4QezxderKX"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Train **all** models on the train set.\n",
        "* Evaluate **all** models on the validation set.\n",
        "* Compute metrics on the validation set.\n",
        "* Pick **at least** three seeds for robust estimation.\n",
        "* Pick the **best** performing model according to the observed validation set performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0WUHlsherKX"
      },
      "source": [
        "**NB: todo fine tuning on embedding layer https://stackoverflow.com/questions/40345607/how-does-fine-tuning-word-embeddings-work**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "HF42CZqRh6Ij"
      },
      "outputs": [],
      "source": [
        "train = True\n",
        "\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, min_lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T18:55:46.439836Z",
          "iopub.status.busy": "2023-11-20T18:55:46.438962Z",
          "iopub.status.idle": "2023-11-20T19:13:32.641236Z",
          "shell.execute_reply": "2023-11-20T19:13:32.640409Z",
          "shell.execute_reply.started": "2023-11-20T18:55:46.439797Z"
        },
        "id": "zjgqXJnoBP36",
        "outputId": "1d642ca2-d0b4-4f21-c2e0-65b33ca4688a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "41/41 [==============================] - 9s 179ms/step\n",
            "Macro F1-Score: 0.0195 - Precision: 0.8894 - Recall: 0.0443 - Accuracy: 0.0187\n",
            "31/31 [==============================] - 201s 6s/step - loss: 3.2123 - accuracy: 0.1378 - val_loss: 2.9767 - val_accuracy: 0.1935 - lr: 1.0000\n",
            "Epoch 2/10\n",
            "41/41 [==============================] - 8s 181ms/step\n",
            "Macro F1-Score: 0.0210 - Precision: 0.8506 - Recall: 0.0552 - Accuracy: 0.0208\n",
            "31/31 [==============================] - 101s 3s/step - loss: 2.8642 - accuracy: 0.2024 - val_loss: 2.7847 - val_accuracy: 0.2159 - lr: 1.0000\n",
            "Epoch 3/10\n",
            "41/41 [==============================] - 10s 243ms/step\n",
            "Macro F1-Score: 0.0288 - Precision: 0.7790 - Recall: 0.0584 - Accuracy: 0.0207\n",
            "31/31 [==============================] - 111s 4s/step - loss: 2.6933 - accuracy: 0.2434 - val_loss: 2.8042 - val_accuracy: 0.2144 - lr: 1.0000\n",
            "Epoch 4/10\n",
            "41/41 [==============================] - 9s 223ms/step\n",
            "Macro F1-Score: 0.1051 - Precision: 0.6476 - Recall: 0.1375 - Accuracy: 0.0391\n",
            "31/31 [==============================] - 102s 3s/step - loss: 2.4603 - accuracy: 0.3071 - val_loss: 2.1884 - val_accuracy: 0.4054 - lr: 1.0000\n",
            "Epoch 5/10\n",
            "41/41 [==============================] - 9s 213ms/step\n",
            "Macro F1-Score: 0.1190 - Precision: 0.7297 - Recall: 0.1377 - Accuracy: 0.0388\n",
            "31/31 [==============================] - 96s 3s/step - loss: 2.1057 - accuracy: 0.3928 - val_loss: 1.9541 - val_accuracy: 0.4027 - lr: 1.0000\n",
            "Epoch 6/10\n",
            "41/41 [==============================] - 9s 211ms/step\n",
            "Macro F1-Score: 0.1659 - Precision: 0.6596 - Recall: 0.2140 - Accuracy: 0.0459\n",
            "31/31 [==============================] - 102s 3s/step - loss: 1.7643 - accuracy: 0.4845 - val_loss: 1.7957 - val_accuracy: 0.4764 - lr: 1.0000\n",
            "Epoch 7/10\n",
            "41/41 [==============================] - 9s 209ms/step\n",
            "Macro F1-Score: 0.2779 - Precision: 0.7663 - Recall: 0.3092 - Accuracy: 0.0584\n",
            "31/31 [==============================] - 95s 3s/step - loss: 1.5427 - accuracy: 0.5451 - val_loss: 1.3909 - val_accuracy: 0.6056 - lr: 1.0000\n",
            "Epoch 8/10\n",
            "41/41 [==============================] - 9s 212ms/step\n",
            "Macro F1-Score: 0.2825 - Precision: 0.7691 - Recall: 0.2912 - Accuracy: 0.0576\n",
            "31/31 [==============================] - 97s 3s/step - loss: 1.3597 - accuracy: 0.6056 - val_loss: 1.3760 - val_accuracy: 0.5973 - lr: 1.0000\n",
            "Epoch 9/10\n",
            "41/41 [==============================] - 8s 206ms/step\n",
            "Macro F1-Score: 0.3286 - Precision: 0.7907 - Recall: 0.3416 - Accuracy: 0.0618\n",
            "31/31 [==============================] - 97s 3s/step - loss: 1.1967 - accuracy: 0.6463 - val_loss: 1.1929 - val_accuracy: 0.6410 - lr: 1.0000\n",
            "Epoch 10/10\n",
            "41/41 [==============================] - 9s 212ms/step\n",
            "Macro F1-Score: 0.3712 - Precision: 0.8069 - Recall: 0.3803 - Accuracy: 0.0651\n",
            "31/31 [==============================] - 96s 3s/step - loss: 1.0842 - accuracy: 0.6781 - val_loss: 1.1098 - val_accuracy: 0.6751 - lr: 1.0000\n"
          ]
        }
      ],
      "source": [
        "model = model_1\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.experimental.Adadelta(learning_rate=1))\n",
        "\n",
        "if not train:\n",
        "    model.load_weights(\"model.h5\")\n",
        "    print(\"Loaded modelfromdisk\")\n",
        "else:\n",
        "    history = model.fit(x_train_pad, y_train_pad, batch_size=batch_size, epochs=10,\n",
        "                        validation_data=(x_val_pad, y_val_pad), verbose=1,\n",
        "                        callbacks=[MetricsCallback(x_val_pad, y_val_pad, ignore_classes), early_stopping, reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlE3i98LhlJN",
        "outputId": "7844e4ea-8cfe-430e-e8ac-5a1636d15452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Savedmodeltodisk\n"
          ]
        }
      ],
      "source": [
        "model.save_weights(\"model.h5\")\n",
        "print(\"Savedmodeltodisk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-20T19:13:41.711551Z",
          "iopub.status.busy": "2023-11-20T19:13:41.706588Z",
          "iopub.status.idle": "2023-11-20T19:14:30.736385Z",
          "shell.execute_reply": "2023-11-20T19:14:30.735457Z",
          "shell.execute_reply.started": "2023-11-20T19:13:41.711502Z"
        },
        "id": "qfR3InKSnDuk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_scores = model.evaluate(x_test_pad, y_test_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-20T19:16:32.905700Z",
          "iopub.status.busy": "2023-11-20T19:16:32.904833Z",
          "iopub.status.idle": "2023-11-20T19:16:39.759496Z",
          "shell.execute_reply": "2023-11-20T19:16:39.758391Z",
          "shell.execute_reply.started": "2023-11-20T19:16:32.905657Z"
        },
        "id": "9PWRk8LIerKX",
        "outputId": "d8ab8e98-8080-46b1-a097-e498d6a90d5b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 7s 315ms/step\n",
            "but some analysts questioned how much of an impact the retirement package will have , because few jobs will end up being eliminated . [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "['CC', 'DT', 'NNS', 'VBD', 'WRB', 'RB', 'IN', 'DT', 'NN', 'DT', 'NN', 'NN', 'MD', 'VB', ',', 'IN', 'JJ', 'NNS', 'MD', 'VB', 'RP', 'VBG', 'VBN', '.', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "['IN', 'DT', 'NNS', 'NNS', 'RB', 'RB', 'IN', 'JJ', 'NN', 'DT', 'JJ', 'NN', 'TO', 'VB', ',', 'RB', 'JJ', 'NNS', 'MD', 'VB', 'IN', 'RB', 'NN', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(x_test_pad)\n",
        "print(decode_phrase(x_test_pad[4]))\n",
        "print(int_to_pos(y_test_pad[4]))\n",
        "print(int_to_pos(pred[4]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyCnuU9Wm1lY"
      },
      "outputs": [],
      "source": [
        "def merge_history(history1, history2):\n",
        "    final_history = {}\n",
        "\n",
        "    for key in history1.keys():\n",
        "        final_history[key] = history1[key] + history2[key]\n",
        "\n",
        "    return final_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kDVRyE6m3hm"
      },
      "outputs": [],
      "source": [
        "# final_history = merge_history(history.history, history_2.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-20T14:33:50.973859Z",
          "iopub.status.idle": "2023-11-20T14:33:50.974190Z",
          "shell.execute_reply": "2023-11-20T14:33:50.974045Z",
          "shell.execute_reply.started": "2023-11-20T14:33:50.974029Z"
        },
        "id": "0dANa_YzerKX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def graph_plots(history, string):\n",
        "  plt.plot(history[string])\n",
        "  plt.plot(history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "graph_plots(history.history, \"accuracy\")\n",
        "graph_plots(history.history, \"loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldnDXMJberKY"
      },
      "source": [
        "# [Task 6 - 1.0 points] Error Analysis\n",
        "\n",
        "You are tasked to evaluate your best performing model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkJt90bTerKY"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Compare the errors made on the validation and test sets.\n",
        "* Aggregate model errors into categories (if possible)\n",
        "* Comment the about errors and propose possible solutions on how to address them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDyrD2lkerKY"
      },
      "source": [
        "# [Task 7 - 1.0 points] Report\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzXPl4a8erKY"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Use the NLP course report template.\n",
        "* Summarize each task in the report following the provided template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwgIk9cMerKY"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "* **Do not** report command outputs or screenshots.\n",
        "* Report learning curves in Figure format.\n",
        "* The error analysis section should summarize your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soQhVYWUerKY"
      },
      "source": [
        "# Submission\n",
        "\n",
        "* **Submit** your report in PDF format.\n",
        "* **Submit** your python notebook.\n",
        "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
        "* You can upload **model weights** in a cloud repository and report the link in the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gvMpihcerKY"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "Please check this frequently asked questions before contacting us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U_Mw939erKY"
      },
      "source": [
        "### Trainable Embeddings\n",
        "\n",
        "You are **free** to define a trainable or non-trainable Embedding layer to load the GloVe embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XipBlZuWerKY"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "You **should not** change the architecture of a model (i.e., its layers).\n",
        "\n",
        "However, you are **free** to play with their hyper-parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxly3ITzerKZ"
      },
      "source": [
        "### Neural Libraries\n",
        "\n",
        "You are **free** to use any library of your choice to implement the networks (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ekET0dqerKZ"
      },
      "source": [
        "### Keras TimeDistributed Dense layer\n",
        "\n",
        "If you are using Keras, we recommend wrapping the final Dense layer with `TimeDistributed`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skoUzF-LerKZ"
      },
      "source": [
        "### Error Analysis\n",
        "\n",
        "Some topics for discussion include:\n",
        "   * Model performance on most/less frequent classes.\n",
        "   * Precision/Recall curves.\n",
        "   * Confusion matrices.\n",
        "   * Specific misclassified samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVnkFOYverKZ"
      },
      "source": [
        "### Punctuation\n",
        "\n",
        "**Do not** remove punctuation from documents since it may be helpful to the model.\n",
        "\n",
        "You should **ignore** it during metrics computation.\n",
        "\n",
        "If you are curious, you can run additional experiments to verify the impact of removing punctuation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FVm4juGerKZ"
      },
      "source": [
        "# The End"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30588,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
